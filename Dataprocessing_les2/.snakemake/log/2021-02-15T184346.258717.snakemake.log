Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 5
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	2	bwa_map
	2

[Mon Feb 15 18:43:46 2021]
Job 0: executing bwa mem on the following data/genome.fa data/samples/A.fastq to generate the following mapped_reads/A.bam


[Mon Feb 15 18:43:46 2021]
Job 1: executing bwa mem on the following data/genome.fa data/samples/B.fastq to generate the following mapped_reads/B.bam

[Mon Feb 15 18:43:46 2021]
Error in rule bwa_map:
    jobid: 0
    output: mapped_reads/A.bam
    shell:
        bwa mem data/genome.fa data/samples/A.fastq | samtools view -Sb - > mapped_reads/A.bam
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job bwa_map since they might be corrupted:
mapped_reads/A.bam
[Mon Feb 15 18:43:46 2021]
Error in rule bwa_map:
    jobid: 1
    output: mapped_reads/B.bam
    shell:
        bwa mem data/genome.fa data/samples/B.fastq | samtools view -Sb - > mapped_reads/B.bam
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job bwa_map since they might be corrupted:
mapped_reads/B.bam
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/bengels/Desktop/Thema11_application_design/dataprocessing/Dataprocessing/Dataprocessing_les2/.snakemake/log/2021-02-15T184346.258717.snakemake.log
